
[[cls_5]]
== Determining combined standard uncertainty

[[scls_5-1]]
=== Uncorrelated input quantities

This subclause treats the case where all input quantities are *independent* (<<scls_C-3-7>>). The case where two or more input quantities are related, that is, are interdependent or *correlated* (<<scls_C-2-8>>), is discussed in <<scls_5-2>>.


[[scls_5-1-1]]
==== {blank}

The standard uncertainty of stem:[y], where stem:[y] is the estimate of the measurand stem:[Y] and thus the result of the measurement, is obtained by appropriately combining the standard uncertainties of the input estimates stem:[x_1,x_2,..., x_N] (see <<scls_4-1>>). This _combined standard uncertainty_ of the estimate stem:[y] is denoted by stem:[u_{"c"}(y)].

NOTE: For reasons similar to those given in the <<note_4-3-1>>, the symbols stem:[u_{"c"}(y)] and stem:[u_{"c"}^2(y)] are used in all cases.


[[scls_5-1-2]]
==== {blank}

The combined standard uncertainty stem:[pu_{"c"}(y)] is the positive square root of the combined variance stem:[u_{"c"}^2(y)], which is given by

[[eq_10]]
[stem]
++++
u_{"c"}^2(y) = sum_{i=1}^N ({partial f}/{partial x_i})^2 u^2(x_i)
++++

where stem:[f] is the function given in <<eq_1>>. Each stem:[u(x_i)] is a standard uncertainty evaluated as described in <<scls_4-2>> (Type A evaluation) or as in <<scls_4-3>> (Type B evaluation). The combined standard uncertainty stem:[u_{"c"}(y)] is an estimated standard deviation and characterizes the dispersion of the values that could reasonably be attributed to the measurand stem:[Y] (see <<scls_2-2-3>>).

<<eq_10>> and its counterpart for correlated input quantities, <<eq_13>>, both of which are based on a first-order Taylor series approximation of stem:[Y = f(X_1, X_2,..., X_N)], express what is termed in this _Guide_ the _law of propagation of uncertainty_ (see <<scls_E-3-1>> and <<scls_E-3-2>>).

[[note_5-1-2]]
[NOTE]
====
When the nonlinearity of stem:[f] is significant, higher-order terms in the Taylor series expansion must be included in the expression for stem:[u_{"c"}^2(y)], <<eq_10>>. When the distribution of each stem:[X_i] is normal, the most important terms of next highest order to be added to the terms of <<eq_10>> are

[stem%unnumbered]
++++
sum_{i=1}^N sum_{j=1}^N [1/2 ({partial^2 f}/{partial x_i partial x_j})^2 + {partial f}/{partial x_i} {partial^3 f}/{partial x_i partial x_j^2}] u^2(x_i) u^2(x_j)
++++

See <<scls_H-1>> for an example of a situation where the contribution of higher-order terms to stem:[u_{"c"}^2(y)] needs to be considered.
====

[[scls_5-1-3]]
==== {blank}

The partial derivatives stem:[partial f//partial x_i] are equal to stem:[partial f//partial X_i] evaluated at stem:[X_i = x_i] (see <<note1_5-1-3>> below). These derivatives, often called sensitivity coefficients, describe how the output estimate stem:[y] varies with changes in the values of the input estimates stem:[x_1, x_2,..., x_N]. In particular, the change in stem:[y] produced by a small change stem:[Delta x_i] in input estimate stem:[x_i] is given by stem:[(Delta y)_i = (partial f//partial x_i)(Delta x_i)]. If this change is generated by the standard uncertainty of the estimate stem:[x_i], the corresponding variation in stem:[y] is stem:[(partial f//partial x_i) u(x_i)]. The combined variance stem:[u_{"c"}^2(y)] can therefore be viewed as a sum of terms, each of which represents the estimated variance associated with the output estimate stem:[y] generated by the estimated variance associated with each input estimate stem:[x_i]. This suggests writing <<eq_10>> as

[[eq_11a]]
[stem]
++++
u_{"c"}^2(y) = sum_{i=1}^N [c_i u(x_i)]^2 -= sum_{i=1}^N u_i^2(y)
++++

where

[[eq_11b]]
[stem]
++++
c_i -= partial f//partial x_i, " " " " u_i(y) -= |c_i|u(x_i)
++++

[[note1_5-1-3]]
[NOTE]
====
Strictly speaking, the partial derivatives are stem:[partial f//partial x_i = partial f//partial X_i] evaluated at the expectations of the stem:[X_i]. However, in practice, the partial derivatives are estimated by

[stem%unnumbered]
++++
{partial f}/{partial x_i} = |: {partial f}/{partial X_i} |_{x_1,x_2,...,x_N}
++++
====

[[note2_5-1-3]]
[NOTE]
====
The combined standard uncertainty stem:[u_{"c"}(y)] may be calculated numerically by replacing stem:[c_i u(x_i)] in <<eq_11a>> with

[stem%unnumbered]
++++
Z_i = 1/2 {f[x_1,...,x_i + u(x_i),...,x_N] - f[x_1,...,x_i - u(x_i),...,x_N]}
++++

That is, stem:[u_i(y)] is evaluated numerically by calculating the change in stem:[y] due to a change in stem:[x_i] of stem:[+u(x_i)] and of stem:[-u(x_i)]. The value of stem:[u_i(y)] may then be taken as stem:[|Z_i|] and the value of the corresponding sensitivity coefficient stem:[c_i] as stem:[Z_i//u(x_i)].
====

[example]
====
For the example of <<scls_4-1-1>>, using the same symbol for both the quantity and its estimate for simplicity of notation,

[stem%unnumbered]
++++
{:({:c_1:},{:-= partial P//partial V = 2V//{R_0 [1 + alpha(t - t_0)]} = 2 P//V:}),
({:c_2:},{:-= partial P//partial R_0 = -V^2//{R_0^2 [1 + alpha(t - t_0)]} = -P//R_0:}),
({:c_3:},{:-= partial P//partial alpha = -V^2 (t - t_0)//{R_0[1 + alpha(t - t_0)]^2} = -P(t - t_0)//[1 + alpha(t - t_0)]:}),
({:c_4:},{:-= partial P//partial t = -V^2 alpha//{R_0[1 + alpha(t - t_0)]^2} = -P alpha//[1 + alpha(t - t_0)]:}):}
++++

and

[stem%unnumbered]
++++
{:({:u^2(P):},{:= ({partial P}/{partial V})^2 u^2(V) + ({partial P}/{partial R_0})^2 u^2(R_0) + ({partial P}/{partial alpha})^2 u^2(alpha) + ({partial P}/{partial t})^2 u^2(t):}),
({:"":},{:= [c_1 u(V)]^2 + [c_2 u(R_0)]^2 + [c_3 u(alpha)]^2 + [c_4 u(t)]^2:}),
({:"":},{:= u_1^2(P) + u_2^2(P) + u_3^2(P) + u_4^2(P):}):}
++++

====



[[scls_5-1-4]]
==== {blank}

Instead of being calculated from the function stem:[f], sensitivity coefficients stem:[partial f//partial x_i] are sometimes determined experimentally: one measures the change in stem:[Y] produced by a change in a particular stem:[X_i] while holding the remaining input quantities constant. In this case, the knowledge of the function stem:[f] (or a portion of it when only several sensitivity coefficients are so determined) is accordingly reduced to an empirical first-order Taylor series expansion based on the measured sensitivity coefficients.


[[scls_5-1-5]]
==== {blank}

If <<eq_1>> for the measurand stem:[Y] is expanded about nominal values stem:[X_{i,0}] of the input quantities stem:[X_i], then, to first order (which is usually an adequate approximation), stem:[Y = Y_0 + c_1 delta_1 + c_2 delta_2 + ... + c_N delta_N], where stem:[Y_0 = f(X_{1,0}, X_{2,0},..., X_{N,0})], stem:[c_i = (partial f//partial X_i)] evaluated at stem:[X_i = X_{i,0}], and stem:[delta_i = X_i - X_{i,0}]. Thus, for the purposes of ananalysis of uncertainty, a measurand is usually approximated by a linear function of its variables by transforming its input quantities from stem:[X_i] to stem:[delta_i] (see <<scls_E-3-1>>).

[example]
====
From <<example2_4-3-7>> of <<scls_4-3-7>>, the estimate of the value of the measurand stem:[V] is stem:[V = V + Delta_{ii(V)}], where stem:[V = 0.928571" V"], stem:[u(V)=12" "mu"V"], the additive correction stem:[Delta_{ii(V)} = 0], and stem:[u (Delta_{ii(V)}) = 8.7" "mu"V"]. Since stem:[partial V//partial bar(V) = 1], and stem:[partial V//partial (Delta_{bar(V)}) = 1], the combined variance associated with stem:[ii(V)] is given by

[stem%unnumbered]
++++
u_{"c"}^2 (ii{V}) = u^2 (bar(ii{V})) + u^2 (Delta bar(ii{V})) = (12" "mu rm(V))^2 + (8.7" "murm(V))^2 = 219 xx 10^{-12}" "rm(V)^2
++++

and the combined standard uncertainty is stem:[u_{"c"}(V) = 15" "mu"V"], which corresponds to a relative combined standard uncertainty stem:[u_{"c"}(V)//V] of stem:[16 xx 10^{-6}] (see <<scls_5-1-6>>). This is an example of the case where the measurand is already a linear function of the quantities on which it depends, with coefficients stem:[c_i = +1]. It follows from <<eq_10>> that if stem:[Y = c_1X_1 + c_2X_2 +... + c_NX_N] and if the constants stem:[c_i = +1 or -1], then stem:[u_{"c"}^2 (y) = sum_{i=1}^{N} u^2 (x_i)].
====


[[scls_5-1-6]]
==== {blank}

If stem:[Y] is of the form stem:[Y = c X_1^{p1} X_2^{p2} ... X_N^{pN}] and the exponents stem:[p_i] are known positive or negative numbers having negligible uncertainties, the combined variance, <<eq_10>>, can be expressed as

[[eq_12]]
[stem]
++++
[u_{"c"} (y)//y]^2 = sum_{i=1}^N [p_i u(x_i)//x_i]^2
++++

This is of the same form as <<eq_11a>> but with the combined variance stem:[u_{"c"}^2(y)] expressed as a _relative combined variance_ stem:[[u_{"c"}(y)//y\]^2] and the estimated variance stem:[u^2(x_i)] associated with each input estimate expressed as an estimated _relative variance_ stem:[[u(x_i)//x_i\]^2]. [The _relative combined standard uncertainty_ is stem:[u_{"c"}(y)//│y│] and the _relative standard uncertainty_ of each input estimate is stem:[u(x_i)//│x_i│], stem:[│y│ != 0] and stem:[│x_i│ != 0].]


NOTE: When stem:[Y] has this form, its transformation to a linear function of variables (see <<scls_5-1-5>>) is readily achieved by
setting stem:[X_i = X_{i,0} (1 + delta_i)], for then the following approximate relation results: stem:[(Y - Y_0) Y_0 = sum_{i=1}^N p_i delta_i].
On the other hand, the logarithmic transformation stem:[Z = ln Y] and stem:[W_i = ln X_i] leads to an exact linearization in terms of the new variables:
stem:[Z = ln c + sum_{i=1}^N  p_i W_i].


[[note2_5-1-6]]
NOTE: If each stem:[p_i] is either +1 or -1, <<eq_12>> becomes stem:[[u_{"c"}(y)//y\]^2 = sum_{i=1}^N [u(x_i)//x_i\]], which shows that, for this
special case, the relative combined variance associated with the estimate stem:[y] is simply equal to the sum of the estimated relative variances associated with the input estimates stem:[x_i].


[[scls_5-2]]
=== Correlated input quantities

[[scls_5-2-1]]
==== {blank}

<<eq_10>> and those derived from it such as <<eq_11a>> and <<eq_12>> are valid only if the input quantities stem:[X_i] are independent or uncorrelated (the random variables, not the physical quantities that are assumed to be invariants -- see <<note1_4-1-1>>). If some of the stem:[X_i] are significantly correlated, the correlations must be taken into account.


[[scls_5-2-2]]
==== {blank}

When the input quantities are correlated, the appropriate expression for the combined variance stem:[u_{"c"}^2(y)] associated with the result of a measurement is

[[eq_13]]
[stem]
++++
u_{"c"}^2(y) = sum_{i=1}^N sum_{j=1}^N {partial f}/{partial x_i} {partial f}/{partial x_j} u(x_i,x_j) = sum_{i=1}^N ({partial f}/{partial x_i})^2 u^2(x_i) + 2 sum_{i=1}^{N-1} sum_{j=i+1}^N {partial f}/{partial x_j} {partial f}/{partial x_j} u(x_i,x_j)
++++

where stem:[x_i] and stem:[x_j] are the estimates of stem:[X_i] and stem:[X_j] and stem:[u(x_i,x_j) = u(x_j,x_i)] is the estimated covariance associated with stem:[x_i] and stem:[x_j]. The degree of correlation between stem:[x_i] and stem:[x_j] is characterized by the estimated *correlation coefficient* (<<scls_C-3-6>>)

[[eq_14]]
[stem]
++++
r(x_i,x_j) = {u(x_i,x_j)}/{u(x_i)u(x_j)}
++++

where stem:[r (x_i,x_j) = r (x_j, x_i)], and stem:[-1 <= r(x_i,x_j) <= +1]. If the estimates stem:[x_i] and stem:[x_j] are independent, stem:[r(x_i,x_j) = 0], and a change in one does not imply an expected change in the other. (See <<scls_C-2-8>>, <<scls_C-3-6>>, and <<scls_C-3-7>> for further discussion.)

In terms of correlation coefficients, which are more readily interpreted than covariances, the covariance term of <<eq_13>> may be written as

[[eq_15]]
[stem]
++++
2 sum_{i=1}^{N-1} sum_{j=i+1}^N {partial f}/{partial x_i} {partial f}/{partial x_j} u(x_i) u(x_j) r(x_i,x_j)
++++

<<eq_13>> then becomes, with the aid of <<eq_11b>>,

[[eq_16]]
[stem]
++++
u_{"c"}^2(y) = sum_{i=1}^N c_i^2 u^2(x_i) + 2 sum_{i=1}^{N-1} sum_{j=i+1}^N c_i c_j u(x_i) u(x_j) r(x_i,x_j)
++++

[[note1_5-2-2]]
[NOTE]
====
For the very special case where _all_ of the input estimates are correlated with correlation coefficients stem:[r(x_i,x_j)= +1], <<eq_16>> reduces to

[stem%unnumbered]
++++
u_{"c"}^2(y) = [sum_{i=1}^N c_i u(x_i)]^2 = [sum_{i=1}^N {partial f}/{partial x_i} u(x_i)]^2
++++

The combined standard uncertainty stem:[u_{"c"}(y)] is thus simply a _linear sum_ of terms representing the variation of the output estimate stem:[y] generated by the standard uncertainty of each input estimate stem:[x_i] (see <<scls_5-1-3>>). [This linear sum should not be confused with the general law of error propagation although it has a similar form; standard uncertainties are not errors (see <<scls_E-3-2>>).]
====

[[example_5-2-2]]
[example]
Ten resistors, each of nominal resistance stem:[R_i = 1000" "Omega], are calibrated with a negligible uncertainty of comparison in terms of the same stem:[1000" "Omega] standard resistor stem:[R_s] characterized by a standard uncertainty stem:[u(R_s) = 100" m"Omega] as given in its calibration certificate. The resistors are connected in series with wires having negligible resistance in order to obtain a reference resistance stem:[R_{"ref"}] of nominal value stem:[10" k"Omega]. Thus
stem:[R_{"ref"} = f (R_i) = sum_{i=1}^10 R_i]. Since stem:[r(x_i,x_j) = r(R_i,R_j) = +1] for each resistor pair (see <<scls_F-1-2-3>>, <<example2_F-1-2-3>>), the equation of this note applies. Since for each resistor stem:[partial f // partial x_i = partial R_{"ref"}// partial R_i = 1], and stem:[u(x_i) = u(R_i) = u(R_s)] (see <<scls_F-1-2-3>>, <<example2_F-1-2-3>>), that equation yields for the combined standard uncertainty of stem:[R_{"ref"}], stem:[u_{"c"}(R_{"ref"}) = sum_{i=1}^10 u (R_s) = 10 xx (100" "m Omega) = 1" "Omega]. The result stem:[u_{"c"}(R_{"ref"}) = [sum_{i=1}^10 u^2 (R_s)\]^{1//2} = 0.32" "Omega] obtained from <<eq_10>> is incorrect because it does not take into account that all of the calibrated values of the ten resistors are correlated.


[[note2_5-2-2]]
NOTE: The estimated variances stem:[u^2(x_i)] and estimated covariances stem:[u(x_i, x_j)] may be considered as the elements of a covariance matrix with elements stem:[u_{ij}]. The diagonal elements stem:[u_{i i}] of the matrix are the variances stem:[u^2(x_i)], while the off-diagonal elements stem:[u_{ij} (i != j)] are the covariances stem:[u(x_i,x_j) = u(x_j,x_i)]. If two input estimates are uncorrelated, their associated covariance and the corresponding elements stem:[u_{ij}] and stem:[u_{ji}] of the covariance matrix are 0. If the input estimates are all uncorrelated, all of the off-diagonal elements are zero and the covariance matrix is diagonal. (See also <<scls_C-3-5>>.)


[NOTE]
====
For the purposes of numerical evaluation, <<eq_16>> may be written as

[stem%unnumbered]
++++
u_{"c"}^2(y) = sum_{i=1}^N sum_{j=1}^N Z_i Z_j r(x_i,x_j)
++++

where stem:[Z_i] is given in <<note2_5-1-3>>.
====

[NOTE]
====
If the stem:[X_i] of the special form considered in <<scls_5-1-6>> are correlated, then the terms

[stem%unnumbered]
++++
2 sum_{i=1}^{N-1} sum_{j=i+1}^N [p_i u(x_i)//x_i][p_j u(x_j)//x_j] r(x_i,r_j)
++++

must be added to the right-hand side of <<eq_12>>.
====

[[scls_5-2-3]]
==== {blank}

Consider two arithmetic means stem:[bar(q)] and stem:[bar(r)] that estimate the expectations stem:[mu_q] and stem:[mu_r] of two randomly varying quantities stem:[q] and stem:[r], and let stem:[bar(q)] and stem:[bar(r)] be calculated from stem:[n] independent pairs of simultaneous observations of stem:[q] and stem:[r] made under the same conditions of measurement (see <<scls_B-2-15>>). Then the covariance (see <<scls_C-3-4>>) of stem:[bar(q)] and stem:[bar(r)] is estimated by

[[eq_17]]
[stem]
++++
s(bar(q),bar(r)) = 1/{n(n-1)} sum_{k=1}^n (q_k - bar(q))(r_k - bar(r))
++++

where stem:[q_k] and stem:[r_k] are the individual observations of the quantities stem:[q] and stem:[r] and stem:[bar(q)] and stem:[bar(r)] are calculated from the observations according to <<eq_3>>. If in fact the observations are uncorrelated, the calculated covariance is expected to be near 0.

Thus the estimated covariance of two correlated input quantities stem:[X_i] and stem:[X_j] that are estimated by the means
stem:[bar(X)_i] and stem:[bar(X)_j] determined from independent pairs of repeated simultaneous observations is given by
stem:[u(x_i,x_j) = s(bar(X)_i,bar(X)_j)], with stem:[s(bar(X)_i,bar(X)_j)] calculated according to <<eq_17>>. This application of <<eq_17>> is a Type A evaluation of covariance. The estimated correlation coefficient of stem:[bar(X)_i] and stem:[bar(X)_j] is obtained from
<<eq_14>>: stem:[r(x_i,x_j) = r(bar(X)_i,bar(X)_j) = s(bar(X)_i,bar(X)_j)//[ s(bar(X)_i) s(bar(X)_j)\]]

NOTE: Examples where it is necessary to use covariances as calculated from <<eq_17>> are given in <<scls_H-2>> and <<scls_H-4>>.


[[scls_5-2-4]]
==== {blank}

There may be significant correlation between two input quantities if the same measuring instrument, physical measurement standard, or reference datum having a significant standard uncertainty is used in their determination. For example, if a certain thermometer is used to determine a temperature correction required in the estimation of the value of input quantity stem:[X_i], and the same thermometer is used to determine a similar temperature correction required in the estimation of input quantity stem:[X_j], the two input quantities could be significantly correlated. However, if stem:[X_i] and stem:[X_j] in this example are redefined to be the uncorrected quantities and the quantities that define the calibration curve for the thermometer are included as additional input quantities with independent standard uncertainties, the correlation between stem:[X_i] and stem:[X_j] is removed. (See <<scls_F-1-2-3>> and <<scls_F-1-2-4>> for further discussion.)


[[scls_5-2-5]]
==== {blank}

Correlations between input quantities cannot be ignored if present and significant. The associated covariances should be evaluated experimentally if feasible by varying the correlated input quantities (see <<note3_C-3-6>>), or by using the pool of available information on the correlated variability of the quantities inquestion (Type B evaluation of covariance). Insight based on experience and general knowledge (see <<scls_4-3-1>> and <<scls_4-3-2>>) is especially required when estimating the degree of correlation between input quantities arising from the effects of common influences, such as ambient temperature, barometric pressure, and humidity. Fortunately, in many cases, the effects of such influences have negligible interdependence and the affected input quantities can be assumed to be uncorrelated. However, if they cannot be assumed to be uncorrelated, the correlations themselves can be avoided if the common influences are introduced as additional independent input quantities as indicated in <<scls_5-2-4>>.
